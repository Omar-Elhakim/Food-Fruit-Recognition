{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13924410,"sourceType":"datasetVersion","datasetId":8873182},{"sourceId":13962812,"sourceType":"datasetVersion","datasetId":8900767}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torchvision import datasets, transforms,models\nfrom torch.utils.data import ConcatDataset\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom PIL import Image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:54:25.078998Z","iopub.execute_input":"2025-12-07T19:54:25.079890Z","iopub.status.idle":"2025-12-07T19:54:25.084550Z","shell.execute_reply.started":"2025-12-07T19:54:25.079862Z","shell.execute_reply":"2025-12-07T19:54:25.083793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:54:25.571163Z","iopub.execute_input":"2025-12-07T19:54:25.571910Z","iopub.status.idle":"2025-12-07T19:54:25.576404Z","shell.execute_reply.started":"2025-12-07T19:54:25.571884Z","shell.execute_reply":"2025-12-07T19:54:25.575671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:54:25.594298Z","iopub.execute_input":"2025-12-07T19:54:25.594536Z","iopub.status.idle":"2025-12-07T19:54:25.598562Z","shell.execute_reply.started":"2025-12-07T19:54:25.594519Z","shell.execute_reply":"2025-12-07T19:54:25.597696Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load the Training images","metadata":{}},{"cell_type":"code","source":"def ignore_masks(path):\n    return \"mask\" not in path.lower()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:54:25.599913Z","iopub.execute_input":"2025-12-07T19:54:25.600184Z","iopub.status.idle":"2025-12-07T19:54:25.614820Z","shell.execute_reply.started":"2025-12-07T19:54:25.600167Z","shell.execute_reply":"2025-12-07T19:54:25.613998Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preparation for Fruit Multi-Class Classification","metadata":{}},{"cell_type":"code","source":"fruit_multiclass_train = datasets.ImageFolder(\n    root=r\"/kaggle/input/food-fruit-dataset/Project Data/Fruit/Train\",\n    transform=transforms,\n    is_valid_file=ignore_masks\n)\n\nfruit_multiclass_val = datasets.ImageFolder(\n    root=r\"/kaggle/input/food-fruit-dataset/Project Data/Fruit/Validation\",\n    transform=transforms,\n    is_valid_file=ignore_masks\n)\n\n# 4. Create the Loaders\nfruit_train_loader = DataLoader(fruit_multiclass_train, batch_size=32, shuffle=True)\nfruit_val_loader = DataLoader(fruit_multiclass_val, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:54:25.681105Z","iopub.execute_input":"2025-12-07T19:54:25.681880Z","iopub.status.idle":"2025-12-07T19:54:26.821132Z","shell.execute_reply.started":"2025-12-07T19:54:25.681847Z","shell.execute_reply":"2025-12-07T19:54:26.820291Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Visualize a batch","metadata":{}},{"cell_type":"code","source":"fruit_names = fruit_multiclass_train.classes\n\ndata_iter = iter(fruit_train_loader)\nimages, labels = next(data_iter)\n\nfig = plt.figure(figsize=(12, 12))\n\nfor i in range(16):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    \n    img_display = images[i].numpy().transpose((1, 2, 0))\n    plt.imshow(img_display)\n    idx = labels[i].item()\n    real_name = fruit_names[idx]\n    \n    ax.set_title(f\"{idx}: {real_name}\", color=\"green\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:54:26.822403Z","iopub.execute_input":"2025-12-07T19:54:26.822903Z","iopub.status.idle":"2025-12-07T19:54:27.875422Z","shell.execute_reply.started":"2025-12-07T19:54:26.822884Z","shell.execute_reply":"2025-12-07T19:54:27.874485Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **training**","metadata":{}},{"cell_type":"code","source":"model = models.resnet18(pretrained=True)\n\n# freeze all layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n# replace the last layer with the 30 class\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 30)\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:54:27.876348Z","iopub.execute_input":"2025-12-07T19:54:27.876553Z","iopub.status.idle":"2025-12-07T19:54:28.090054Z","shell.execute_reply.started":"2025-12-07T19:54:27.876537Z","shell.execute_reply":"2025-12-07T19:54:28.089266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:54:28.091569Z","iopub.execute_input":"2025-12-07T19:54:28.091797Z","iopub.status.idle":"2025-12-07T19:54:28.096020Z","shell.execute_reply.started":"2025-12-07T19:54:28.091779Z","shell.execute_reply":"2025-12-07T19:54:28.095175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 10\n\nfor epoch in range(num_epochs):\n\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n    \n    for images, labels in fruit_train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n        z, preds = torch.max(outputs, 1)\n        running_corrects += torch.sum(preds == labels.data)\n    \n    epoch_loss = running_loss / len(fruit_multiclass_train)\n    epoch_acc = running_corrects.double() / len(fruit_multiclass_train)\n    \n    # Validation \n    model.eval()\n    val_corrects = 0\n    with torch.no_grad():\n        for images, labels in fruit_val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            z, preds = torch.max(outputs, 1)\n            val_corrects += torch.sum(preds == labels.data)\n    \n    val_acc = val_corrects.double() / len(fruit_multiclass_val)\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}: \"\n          f\"Train Loss: {epoch_loss:.4f} \"\n          f\"Train Acc: {epoch_acc:.4f} \"\n          f\"Val Acc: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:54:28.097579Z","iopub.execute_input":"2025-12-07T19:54:28.097785Z","iopub.status.idle":"2025-12-07T19:57:23.564491Z","shell.execute_reply.started":"2025-12-07T19:54:28.097769Z","shell.execute_reply":"2025-12-07T19:57:23.563777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"fruit_model.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:57:23.565293Z","iopub.execute_input":"2025-12-07T19:57:23.565624Z","iopub.status.idle":"2025-12-07T19:57:23.659594Z","shell.execute_reply.started":"2025-12-07T19:57:23.565606Z","shell.execute_reply":"2025-12-07T19:57:23.658842Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # **Testing** ","metadata":{}},{"cell_type":"code","source":"def test_image(img_path, model_path=\"fruit_model.pth\", class_names=fruit_names):\n    \n    # Load image\n    img = Image.open(img_path).convert(\"RGB\")\n    img_tensor = transforms(img).unsqueeze(0).to(device)\n    \n    # Load model\n    model_test = models.resnet18(weights=None)\n    num_ftrs = model_test.fc.in_features\n    model_test.fc = nn.Linear(num_ftrs, 30)\n    \n    model_test.load_state_dict(torch.load(model_path, map_location=device))\n    model_test.to(device)\n    model_test.eval()\n    \n    # Predict\n    with torch.no_grad():\n        outputs = model_test(img_tensor)\n        z, predict = torch.max(outputs, 1)\n\n    predicted_class = class_names[predict.item()]\n    print(f\"Predicted Class: {predicted_class}\")\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:57:23.660580Z","iopub.execute_input":"2025-12-07T19:57:23.661328Z","iopub.status.idle":"2025-12-07T19:57:23.666865Z","shell.execute_reply.started":"2025-12-07T19:57:23.661302Z","shell.execute_reply":"2025-12-07T19:57:23.666279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_image(\"/kaggle/input/tst-imgg/tofa7a.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T19:57:23.667608Z","iopub.execute_input":"2025-12-07T19:57:23.668438Z","iopub.status.idle":"2025-12-07T19:57:23.969994Z","shell.execute_reply.started":"2025-12-07T19:57:23.668419Z","shell.execute_reply":"2025-12-07T19:57:23.969242Z"}},"outputs":[],"execution_count":null}]}